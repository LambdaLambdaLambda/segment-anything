\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{ESCA_dataset}
Alessandrini, M., Calero Fuentes~Rivera, R., Falaschetti, L., Pau, D.,
  Tomaselli, V., Turchetti, C.: Esca-dataset. Mendeley Data, V1,
  \url{https://data.mendeley.com/datasets/89cnxc58kj/1} (2021). \doi{doi:
  10.17632/89cnxc58kj.1}

\bibitem{badrinarayanan2016segnet}
Badrinarayanan, V., Kendall, A., Cipolla, R.: Segnet: A deep convolutional
  encoder-decoder architecture for image segmentation. In: Proceedings of the
  IEEE conference on computer vision and pattern recognition. pp. 1843--1851
  (2016)

\bibitem{brostow2009semantic}
Brostow, G.J., Fauqueur, J., Cipolla, R.: Semantic object classes in video: A
  high-definition ground truth database. In: IEEE conference on computer vision
  and pattern recognition. pp. 2366--2373. IEEE (2009)

\bibitem{GPT-3}
Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.: Language models
  are few-shot learners. arXiv preprint arXiv:2005.14165  (2020)

\bibitem{chen2017deeplab}
Chen, L.C., Papandreou, G., Schroff, F., Adam, H.: Deeplab: Semantic image
  segmentation with deep convolutional nets, atrous convolution, and fully
  connected crfs. IEEE transactions on pattern analysis and machine
  intelligence  \textbf{40}(4),  834--848 (2017)

\bibitem{codella2019skin}
Codella, N.C., Rotemberg, V., Tschandl, P., Visconti, A., Helba, B., Sinz, C.,
  Celebi, M.E., Dusza, S., Gutman, D., Halpern, A., et~al.: Skin lesion
  analysis toward melanoma detection: A challenge at the 2017 international
  symposium on biomedical imaging (isbi), hosted by the international skin
  imaging collaboration (isic). IEEE transactions on medical imaging
  \textbf{38}(2),  285--295 (2019)

\bibitem{cordts2016cityscapes}
Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
  Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban
  scene understanding. In: Proceedings of the IEEE conference on computer
  vision and pattern recognition. pp. 3213--3223 (2016)

\bibitem{deepglobe_land_cover}
Demir, I., Koperski, K., Lindenbaum, D., Pang, G., Huang, J., Basu, S., Hughes,
  F., Tuia, D., Raskar, R., Kress, W., et~al.: Deepglobe 2018: A challenge to
  parse the earth through satellite images. In: Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition Workshops. pp. 172--173
  (2018)

\bibitem{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A
  large-scale hierarchical image database. 2009 IEEE conference on computer
  vision and pattern recognition pp. 248--255 (2009)

\bibitem{ViT2020}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.:
  An image is worth 16x16 words: Transformers for image recognition at scale.
  In: International Conference on Learning Representations (2020)

\bibitem{everingham2010pascal}
Everingham, M., Van~Gool, L., Williams, C.K., Winn, J., Zisserman, A.: The
  pascal visual object classes (voc) challenge. International journal of
  computer vision  \textbf{88}(2),  303--338 (2010)

\bibitem{he2016resnet}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition. pp. 770--778 (2016)

\bibitem{SA-1B_dataset}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.C., Lo, W.Y., et~al.: Available at:
  \url{https://ai.facebook.com/datasets/segment-anything-downloads/}

\bibitem{2023-SAM-Meta}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.C., Lo, W.Y., et~al.: Segment anything. arXiv
  preprint arXiv:2304.02643  (2023)

\bibitem{ViT-H}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.C., Lo, W.Y., et~al.: Vit-h sam model (May 2023),
  available at:
  \url{https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth}
  (May. 2023)

\bibitem{krizhevsky2012alexnet}
Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep
  convolutional neural networks. Communications of the ACM  \textbf{60}(6),
  84--90 (2012)

\bibitem{landman2012miccai}
Landman, B.A., Warfield, S.K.: Miccai 2012 grand challenge and workshop on
  multi-atlas labeling. In: Medical Image Computing and Computer-Assisted
  Intervention -- MICCAI 2012. pp. 451--460. Springer (2012)

\bibitem{le2022cell}
Le~Dinh, T., Lee, S.H., Kwon, S.G., Kwon, K.R.: Cell nuclei segmentation in
  cryonuseg dataset using nested unet with efficientnet encoder. In: 2022
  International Conference on Electronics, Information, and Communication
  (ICEIC). pp.~1--4. IEEE (2022)

\bibitem{plantclef}
Ligterink, W., M{\"u}ller, H., Bonnet, P., Moulin, C., Joly, A.: Plantclef: The
  fine-grained visual classification of plant species. CLEF  (2013)

\bibitem{lin2014microsoft}
Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., Zitnick, C.L.: Microsoft coco: Common objects in context.
  European conference on computer vision pp. 740--755 (2014)

\bibitem{cropseg}
Liu, K., Wang, Y., Sun, K., Cao, J.: Cropseg: A cropland segmentation dataset
  and benchmark. In: 2019 IEEE International Conference on Image Processing
  (ICIP). pp. 2536--2540. IEEE (2019)

\bibitem{metric-reload}
Maier-Hein, L., Reinke, A., Godau, P., Tizabi, M.D., B\"uttner, F., et~al.:
  Metrics reloaded: Pitfalls and recommendations for image analysis validation.
  arXiv preprint arXiv:2206.01653  (2022)

\bibitem{McGlinchy2019}
McGlinchy, J., Johnson, B., Muller, B., Joseph, M., Diaz, J.: Application of
  unet fully convolutional neural network to impervious surface segmentation in
  urban environment from high resolution satellite imagery. In: IGARSS 2019 -
  2019 IEEE International Geoscience and Remote Sensing Symposium. pp.
  3915--3918 (2019). \doi{10.1109/IGARSS.2019.8900453}

\bibitem{menze2015miccai}
Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby,
  J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., et~al.: The multimodal
  brain tumor image segmentation benchmark (brats). In: Medical Image Computing
  and Computer-Assisted Intervention -- MICCAI 2015. pp. 317--329. Springer
  (2015)

\bibitem{mohanty2016plantvillage}
Mohanty, S.P., Hughes, D.P., Salath{\'e}, M.: Plantvillage dataset: A publicly
  available dataset for deep learning in agriculture.
  \url{https://doi.org/10.5281/zenodo.235808} (2016), accessed: 2023-05-17

\bibitem{nowakowski_crop_2021}
Nowakowski, A., Mrziglod, J., Spiller, D., Bonifacio, R., Ferrari, I., Mathieu,
  P.P., Garcia-Herranz, M., Kim, D.H.: Crop type mapping by using transfer
  learning. International Journal of Applied Earth Observation and
  Geoinformation  \textbf{98} (2021).
  \doi{https://doi.org/10.1016/j.jag.2021.102313},
  \url{https://www.sciencedirect.com/science/article/pii/S0303243421000209}

\bibitem{paymode_transfer_2022}
Paymode, A.S., Malode, V.B.: Transfer {Learning} for {Multi}-{Crop} {Leaf}
  {Disease} {Image} {Classification} using {Convolutional} {Neural} {Network}
  {VGG}. Artificial Intelligence in Agriculture  \textbf{6},  23--33 (2022).
  \doi{https://doi.org/10.1016/j.aiia.2021.12.002},
  \url{https://www.sciencedirect.com/science/article/pii/S2589721721000416}

\bibitem{QIAO2019104958}
Qiao, Y., Truman, M., Sukkarieh, S.: Cattle segmentation and contour extraction
  based on mask r-cnn for precision livestock farming. Computers and
  Electronics in Agriculture  \textbf{165},  104958 (2019)

\bibitem{CLIP-ICML2021}
Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.: Learning transferable visual
  models from natural language supervision. In: International Conference on
  Machine Learning. pp. 8748--8763 (2021)

\bibitem{redmon2016yolo}
Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once:
  Unified, real-time object detection. Proceedings of the IEEE conference on
  computer vision and pattern recognition pp. 779--788 (2016)

\bibitem{isprs_semantic_labeling}
Richter, S., Vineet, V., Roth, S., Koltun, V.: The isprs 2d semantic labeling
  contest. In: Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition Workshops. pp. 111--117 (2016)

\bibitem{RIEHLE2020105201}
Riehle, D., Reiser, D., Griepentrog, H.W.: Robust index-based semantic
  plant/background segmentation for rgb- images. Computers and Electronics in
  Agriculture  \textbf{169},  105201 (2020).
  \doi{https://doi.org/10.1016/j.compag.2019.105201},
  \url{https://www.sciencedirect.com/science/article/pii/S0168169919314346}

\bibitem{ronneberger2015unet}
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for
  biomedical image segmentation. In: International Conference on Medical Image
  Computing and Computer-Assisted Intervention. pp. 234--241. Springer (2015)

\bibitem{simonyan2015vgg}
Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
  image recognition (2015)

\bibitem{smith_segmentation_2020}
Smith, A.G., Petersen, J., Selvan, R., Rasmussen, C.R.: Segmentation of roots
  in soil with {U}-{Net}. Plant Methods  \textbf{16}(1), ~13 (2020).
  \doi{10.1186/s13007-020-0563-0},
  \url{https://doi.org/10.1186/s13007-020-0563-0}

\bibitem{song2015sun}
Song, S., Lichtenberg, S., Xiao, J.: Sun rgb-d: A rgb-d scene understanding
  benchmark suite. In: IEEE conference on computer vision and pattern
  recognition. pp. 567--576. IEEE (2015)

\bibitem{EfficientNet}
Tan, M., Le, Q.: {E}fficient{N}et: Rethinking model scaling for convolutional
  neural networks. In: Chaudhuri, K., Salakhutdinov, R. (eds.) Proceedings of
  the 36th International Conference on Machine Learning. Proceedings of Machine
  Learning Research, vol.~97, pp. 6105--6114. PMLR (09--15 Jun 2019)

\bibitem{FourierPE-Nips20}
Tancik, M., Srinivasan, P., Mildenhall, B., Fridovich-Keil, S., Raghavan, N.,
  Singhal, U., Ramamoorthi, R., Barron, J., Ng, R.: Fourier features let
  networks learn high frequency functions in low dimensional domains. Advances
  in Neural Information Processing Systems  \textbf{33},  7537--7547 (2020)

\bibitem{attention-Nips17}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
  Kaiser, {\L}., Polosukhin, I.: Attention is all you need. Advances in neural
  Information Processing Systems  \textbf{30} (2017)

\bibitem{10.1145/3209811.3212707}
Wang, A.X., Tran, C., Desai, N., Lobell, D., Ermon, S.: Deep transfer learning
  for crop yield prediction with remote sensing data. In: Proceedings of the
  1st ACM SIGCAS Conference on Computing and Sustainable Societies. COMPASS
  '18, Association for Computing Machinery, New York, NY, USA (2018).
  \doi{10.1145/3209811.3212707}, \url{https://doi.org/10.1145/3209811.3212707}

\bibitem{WANG2021106373}
Wang, C., Du, P., Wu, H., Li, J., Zhao, C., Zhu, H.: A cucumber leaf disease
  severity classification method based on the fusion of deeplabv3+ and u-net.
  Computers and Electronics in Agriculture  \textbf{189},  106373 (2021).
  \doi{https://doi.org/10.1016/j.compag.2021.106373},
  \url{https://www.sciencedirect.com/science/article/pii/S0168169921003902}

\bibitem{2023-SegGPT}
Wang, X., Zhang, X., Cao, Y., Wang, W., Shen, C., Huang, T.: Seggpt: Segmenting
  everything in context. arXiv preprint arXiv:2304.03284  (2023)

\bibitem{YANG2015149}
Yang, W., Wang, S., Zhao, X., Zhang, J., Feng, J.: Greenness identification
  based on hsv decision tree. Information Processing in Agriculture
  \textbf{2}(3),  149--160 (2015).
  \doi{https://doi.org/10.1016/j.inpa.2015.07.003},
  \url{https://www.sciencedirect.com/science/article/pii/S2214317315000347}

\bibitem{yuan_advanced_2022}
Yuan, Y., Chen, L., Wu, H., Li, L.: Advanced agricultural disease image
  recognition technologies: {A} review. Information Processing in Agriculture
  \textbf{9}(1),  48--59 (2022).
  \doi{https://doi.org/10.1016/j.inpa.2021.01.003},
  \url{https://www.sciencedirect.com/science/article/pii/S2214317321000032}

\bibitem{Zeiss23}
Zeiss: Apeer annotate (2023), \url{https://www.apeer.com/app/}

\bibitem{ZHANG202282}
Zhang, H., Peng, Q.: Pso and k-means-based semantic segmentation toward
  agricultural products. Future Generation Computer Systems  \textbf{126},
  82--87 (2022). \doi{https://doi.org/10.1016/j.future.2021.06.059},
  \url{https://www.sciencedirect.com/science/article/pii/S0167739X21002545}

\bibitem{plant_phenotyping_dataset}
Zhang, H., Yang, M., Wang, Y., Wang, H., Ma, T., Li, W., Xia, S., Liu, Y.:
  Plant phenotyping datasets for computer vision. Data  \textbf{4}(2), ~36
  (2019)

\bibitem{crop_deeplab_dataset}
Zhang, S., Tang, H., Zhang, X., Liu, J., Zhang, J., Zhang, J., Lu, H.: Crop
  deeplab: Large-scale crop field parsing from satellite imagery. Remote
  Sensing  \textbf{13}(8), ~1460 (2021)

\bibitem{zhou2017scene}
Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., Torralba, A.: Scene
  parsing through ade20k dataset. In: Proceedings of the IEEE conference on
  computer vision and pattern recognition. pp. 633--641 (2017)

\bibitem{zhuang2020comprehensive}
Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., He, Q.: A
  comprehensive survey on transfer learning (2020)

\bibitem{2023-SEEM}
Zou, X., Yang, J., Zhang, H., Li, F., Li, L., Gao, J., Lee, Y.J.: Segment
  everything everywhere all at once. arXiv preprint arXiv:2304.06718  (2023)

\end{thebibliography}
