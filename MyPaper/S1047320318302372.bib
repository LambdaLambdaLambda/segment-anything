@article{LIAN2018296,
title = {Attention guided U-Net for accurate iris segmentation},
journal = {Journal of Visual Communication and Image Representation},
volume = {56},
pages = {296-304},
year = {2018},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1047320318302372},
author = {Sheng Lian and Zhiming Luo and Zhun Zhong and Xiang Lin and Songzhi Su and Shaozi Li},
keywords = {Iris segmentation, U-Net, Attention},
abstract = {Iris segmentation is a critical step for improving the accuracy of iris recognition, as well as for medical concerns. Existing methods generally use whole eye images as input for network learning, which do not consider the geometric constrain that iris only occur in a specific area in the eye. As a result, such methods can be easily affected by irrelevant noisy pixels outside iris region. In order to address this problem, we propose the ATTention U-Net (ATT-UNet) which guides the model to learn more discriminative features for separating the iris and non-iris pixels. The ATT-UNet firstly regress a bounding box of the potential iris region and generated an attention mask. Then, the mask is used as a weighted function to merge with discriminative feature maps in the model, making segmentation model pay more attention to iris region. We implement our approach on UBIRIS.v2 and CASIA.IrisV4-distance, and achieve mean error rates of 0.76% and 0.38%, respectively. Experimental results show that our method achieves consistent improvement in both visible wavelength and near-infrared iris images with challenging scenery, and surpass other representative iris segmentation approaches.}
}